{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b73e3a6",
   "metadata": {},
   "source": [
    "# Day17\n",
    "BERT多任务微调实战，使用bert-large-uncased。[模型信息](https://huggingface.co/google-bert/bert-large-uncased)\n",
    "  - 在GLUE benchmark上进行多任务微调(MNLI/QQP/SST-2)\n",
    "  - 实现任务间的知识迁移和参数共享\n",
    "  - 对比单任务vs多任务性能\n",
    "  - 目标：MNLI准确率≥82%，QQP F1≥85%，SST-2准确率≥90%\n",
    "  \n",
    " * 基础设施搭建\n",
    "    - 多任务数据加载与预处理\n",
    "    - 共享编码器与多任务头设计\n",
    "    - 实现动态任务采样器\n",
    "  \n",
    "  * 多任务训练策略\n",
    "    - PCGrad解决任务冲突\n",
    "    - 梯度累积与归一化\n",
    "  \n",
    "  * 实验任务\n",
    "    - 分类：SST-2情感分析\n",
    "    - 匹配：QQP语义相似度\n",
    "    - 推理：MNLI自然语言推理\n",
    "  \n",
    "  * 训练与评估目标\n",
    "    - SST-2：准确率 ≥ 92%\n",
    "    - QQP：F1 ≥ 85%\n",
    "    - MNLI：准确率 ≥ 82%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa46623",
   "metadata": {},
   "source": [
    "多任务学习（Multi-task Learning - MTL）的核心在于：\n",
    "- 参数共享 (Parameter Sharing): 大部分参数（这里是强大的 BERT 编码器）在多个任务之间共享。这意味着模型学习到的特征表示是通用的，对多个任务都有用。\n",
    "- 知识迁移 (Knowledge Transfer): 通过同时训练多个相关任务，一个任务中学到的知识可以帮助改善其他任务的学习。不同的任务可以提供互补的信息，相当于给模型更多元的“视角”来理解数据。这有助于模型学习到更鲁棒、泛化能力更好的特征表示，并可能在单个任务上表现更好（特别是对于数据量较少的任务）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c2d6e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel\n",
    "import evaluate\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c826525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fb8a4b0fe104b6f8c25c182f842a90d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/52.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b45931da37c4412bb6ca4c9509340c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)alidation_matched-00000-of-00001.parquet:   0%|          | 0.00/1.21M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "944882fadf404ac39656975711bb65dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)dation_mismatched-00000-of-00001.parquet:   0%|          | 0.00/1.25M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a7e3481cf6249eaa270b5d3fb4ee188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test_matched-00000-of-00001.parquet:   0%|          | 0.00/1.22M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a01ca7abbde4824843ccbc770a3a8cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test_mismatched-00000-of-00001.parquet:   0%|          | 0.00/1.26M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a77b844741214199b883236161c03fb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c7b16bb9d614dc590bd563578c62acd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation_matched split:   0%|          | 0/9815 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cb0dd1384504a438e36957e0755ca9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation_mismatched split:   0%|          | 0/9832 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "842ca1f772f14955a272d71cb6e0beee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test_matched split:   0%|          | 0/9796 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99644b6f924343b498319098891950e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test_mismatched split:   0%|          | 0/9847 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d14c1db1add417aac9453167ab11743",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/3.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97f52803b7464162982a6b2d711da2f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/72.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f2cdcc411c645479cf87e1460662aff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/148k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01c43ea52a8c4ebdaaf95e71fd4d41c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/67349 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d794ef6981949c88daf5641d5f54952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f6fe00f64664a95bdbe9dbafe519a46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1821 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "370560138bce4a29a4879556b0228d58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/33.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "768a4cf8d14c401b851d9b4449625ba4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/3.73M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b978a5bd766497da94c74d6143b88cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/36.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aec7b17f6d924da7bf92f63624202bb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/363846 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a8d72b915834d1bb303100b32fa5e5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/40430 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aa79b4654d44441b419a4b90c9798db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/390965 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnli = load_dataset(\"glue\", \"mnli\")\n",
    "sst2 = load_dataset(\"glue\", \"sst2\")\n",
    "qqp = load_dataset(\"glue\", \"qqp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4794aaad",
   "metadata": {},
   "source": [
    "任务特定预处理： 对每个数据集应用 BERT Tokenizer 进行分词、转换为 ID 序列。关键点： 不同任务的输入格式不同！\n",
    "- SST-2: 单句子输入。[CLS] sentence [SEP]\n",
    "- QQP: 句子对输入 (判断语义是否相同)。[CLS] sentence1 [SEP] sentence2 [SEP]\n",
    "- MNLI: 句子对输入 (判断蕴含关系)。[CLS] premise [SEP] hypothesis [SEP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2878fa23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc75a81a1bd34f42be14f1ac20e8db82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da0caabf35db4787b4bf9483697d2335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbfe4ab4e8654875b95d0f6506631dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acb4685e509e40c2a52c5b8aa6fd22ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-large-uncased\",use_fast=True)\n",
    "def tokenize_sst2(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"sentence\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True\n",
    "    )\n",
    "def tokenize_mnli(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"premise\"],\n",
    "        examples[\"hypothesis\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True\n",
    "    )\n",
    "def tokenize_qqp(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"question1\"],\n",
    "        examples[\"question2\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True\n",
    "    )\n",
    "# 如果设置return_tensors=\"pt\"，会返回tensor\n",
    "# 但Huggingface Datasets 的 .map 期望返回 numpy 数组或 list\n",
    "# 可能会会报错或兼容性不好。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "data_preprocessing_unified",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f117d93a83804ab7a98cc3487e6dc069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/67349 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "135d4ef96bd74010bdf4d15158ff1139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "352b0e9ca33c428ab6af4a9e5da1a6ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1821 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "650d73834c6c49b28d385699e7419172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/392702 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8bf7194f7c34c5fae9862fe56aee1c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9815 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e92f25875db48719e060ae561e849d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9832 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ca6ceb7ade149b28e4cbb4458052a20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9796 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dc2e77e7c9e4873b761db945d570e02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9847 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "348202c75d204fe5af013ce5680d8756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/363846 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6293d3ec20e4195b04ccb25e738cedc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/40430 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f1ce3ecb94748f1815aa5de3d8b5de9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/390965 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "task_to_id = {\"mnli\": 0, \"qqp\": 1, \"sst2\": 2}\n",
    "\n",
    "def preprocess_function(examples, task_name):\n",
    "    \"\"\"\n",
    "    按照不同数据集的预处理要求分词，同时标记数据集类型\n",
    "    examples 单个数据集\n",
    "    task_name 数据集名称\n",
    "    \"\"\"\n",
    "    if task_name == \"sst2\":\n",
    "        tokenized_inputs = tokenize_sst2(examples)\n",
    "        tokenized_inputs[\"labels\"] = examples[\"label\"]\n",
    "    elif task_name == \"mnli\":\n",
    "        tokenized_inputs = tokenize_mnli(examples)\n",
    "        tokenized_inputs[\"labels\"] = examples[\"label\"]\n",
    "    elif task_name == \"qqp\":\n",
    "        tokenized_inputs = tokenize_qqp(examples)\n",
    "        tokenized_inputs[\"labels\"] = examples[\"label\"]\n",
    "    else:\n",
    "        raise ValueError(\"Unknown task name\")\n",
    "    # 标记输入属于哪个数据集，在forward中需要这些字段\n",
    "    tokenized_inputs[\"task_id\"] = [task_to_id[task_name]] * len(tokenized_inputs[\"input_ids\"])\n",
    "    tokenized_inputs[\"task_name\"] = [task_name] * len(tokenized_inputs[\"input_ids\"])\n",
    "    return tokenized_inputs\n",
    "\n",
    "\n",
    "processed_sst2 = sst2.map(lambda examples: preprocess_function(examples, \"sst2\"), batched=True)\n",
    "processed_mnli = mnli.map(lambda examples: preprocess_function(examples, \"mnli\"), batched=True)\n",
    "processed_qqp = qqp.map(lambda examples: preprocess_function(examples, \"qqp\"), batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "verify_preprocessing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SST-2 sample structure:\n",
      "dict_keys(['sentence', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask', 'labels', 'task_id', 'task_name'])\n",
      "\n",
      "MNLI sample structure:\n",
      "dict_keys(['premise', 'hypothesis', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask', 'labels', 'task_id', 'task_name'])\n",
      "\n",
      "QQP sample structure:\n",
      "dict_keys(['question1', 'question2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask', 'labels', 'task_id', 'task_name'])\n"
     ]
    }
   ],
   "source": [
    "print(\"SST-2 sample structure:\")\n",
    "print(processed_sst2[\"train\"][0].keys())\n",
    "print(\"\\nMNLI sample structure:\")\n",
    "print(processed_mnli[\"train\"][0].keys())\n",
    "print(\"\\nQQP sample structure:\")\n",
    "print(processed_qqp[\"train\"][0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a0bca5",
   "metadata": {},
   "source": [
    "统一数据格式： 预处理后，每个样本都应该包含：\n",
    "- input_ids: Token ID 序列。\n",
    "- attention_mask: 用于告诉模型哪些是真实 Token，哪些是 Padding。\n",
    "- token_type_ids (可选，但 Bert 常用): 用于区分句子对中的第一个句子和第二个句子。\n",
    "- labels: 任务对应的标签（需要映射为整数 ID）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b421bee1",
   "metadata": {},
   "source": [
    "为每个任务分别创建 DataLoader，训练时轮流取 batch   \n",
    "Huggingface 的 Trainer 会自动把 datasets.Dataset 转成 DataLoader，并自动处理 batch、shuffle、collate 等。你只需要把 train_dataset、eval_dataset 传给 Trainer，不需要手动写 DataLoader。   \n",
    "但如果你要多任务训练（比如轮流训练不同任务），还是建议自己控制训练循环，或者用 Trainer 的自定义 callback 或者多 Trainer 方案。   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d99c029",
   "metadata": {},
   "outputs": [],
   "source": [
    "sst2_loader = DataLoader(\n",
    "    processed_sst2[\"train\"],\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    ")\n",
    "mnli_loader = DataLoader(\n",
    "    processed_mnli[\"train\"],\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    ")\n",
    "qqp_loader = DataLoader(\n",
    "    processed_qqp[\"train\"],\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    ")\n",
    "sst2_eval = DataLoader(\n",
    "    processed_sst2[\"validation\"],\n",
    "    batch_size=8\n",
    ")\n",
    "mnli_eval = DataLoader(\n",
    "    processed_mnli[\"validation_matched\"],\n",
    "    batch_size=8\n",
    ")\n",
    "qqp_eval = DataLoader(\n",
    "    processed_qqp[\"validation\"],\n",
    "    batch_size=8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e692e720",
   "metadata": {},
   "source": [
    "共享编码器与多任务头设计：\n",
    "- 共享编码器： 加载预训练的 BERT 模型主体（通常使用 AutoModel，它只输出特征，不带分类头）。这部分参数在所有任务之间共享。\n",
    "- 多任务头 (Multi-task Heads): 在 BERT 的输出之上，为每个任务添加一个单独的、小的任务特定层（通常是 nn.Linear）。\n",
    "- SST-2 Head: 输入是 BERT 输出的 [CLS] Token 的特征向量，输出 2 个 logits (正面/负面)。\n",
    "- QQP Head: 输入是 BERT 输出的 [CLS] Token 的特征向量，输出 2 个 logits (相似/不相似)。\n",
    "- MNLI Head: 输入是 BERT 输出的 [CLS] Token 的特征向量，输出 3 个 logits (蕴含/矛盾/中性)。\n",
    "- 模型结构： 你的主模型类应该继承 nn.Module。在 __init__ 中实例化共享的 BERT 编码器和每个任务对应的任务头。在 forward 方法中，根据输入的task_id，决定将 BERT 的输出送给哪个任务头，并返回对应的输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1faad30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class model(nn.Module):\n",
    "    def __init__(self, bert_model_name, num_labels_dict):\n",
    "        \"\"\"\n",
    "        bert_model_name: str, 预训练的BERT模型名称\n",
    "        num_labels_dict: dict, 存储数据集名字和输出标签数量的字典，例如 {\"mnli\": 3, \"qqp\": 2, \"sst2\": 2}\n",
    "        \"\"\"\n",
    "        super(model, self).__init__()\n",
    "        # 共享编码器\n",
    "        self.bert = AutoModel.from_pretrained(bert_model_name)\n",
    "\n",
    "        # 多任务头\n",
    "        self.task_heads = nn.ModuleDict() # 使用 ModuleDict 来存储多个任务头\n",
    "        for task_name, num_labels in num_labels_dict.items():\n",
    "             # BERT 的 [CLS] Token 输出维度是 bert.config.hidden_size\n",
    "            self.task_heads[task_name] = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids, task_name):\n",
    "        # 通过共享编码器获取特征表示\n",
    "        # bert_output.last_hidden_state 的形状是 [batch_size, seq_len, hidden_size]\n",
    "        # bert_output.pooler_output 的形状是 [batch_size, hidden_size] (通常是 [CLS] 特征经过一个线性层和Tanh)\n",
    "        # 对于分类任务，通常使用 [CLS] Token 的特征表示\n",
    "        bert_output = self.bert(input_ids=input_ids,\n",
    "                               attention_mask=attention_mask,\n",
    "                               token_type_ids=token_type_ids,\n",
    "                               return_dict=True)\n",
    "        cls_embedding = bert_output.last_hidden_state[:, 0, :] # 取 [CLS] Token 的 embedding (第一个 token)\n",
    "        # 或者使用 pooled_output，取决于bert的实现和你的偏好\n",
    "        # cls_embedding = bert_output.pooler_output\n",
    "\n",
    "\n",
    "        # 根据 task_name 将特征送给对应的任务头\n",
    "        logits = self.task_heads[task_name](cls_embedding)\n",
    "\n",
    "        return logits # 返回对应任务头的输出 logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aab06a5",
   "metadata": {},
   "source": [
    "多任务训练：\n",
    "- 使用梯度累计模拟大批量训练，节省内存\n",
    "- 使用PCGrad，减少不同任务梯度下降时的冲突"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3f1e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "loaders = { \"sst2\":sst2_loader, \"mnli\":mnli_loader, \"qqp\":qqp_loader }\n",
    "epochs = 15\n",
    "accumulation_steps = 4\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model = model(\"bert-large-uncased\", {\"mnli\": 3, \"qqp\": 2, \"sst2\": 2}).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "model.train()\n",
    "best_loss = float(\"inf\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    total_batches = 0\n",
    "    for i,loader in loaders.items():\n",
    "        loop = tqdm(loader, leave=False, desc=f\"Epoch {epoch+1}/{epochs} - {id}\")\n",
    "        for batch in loop:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            token_type_ids = batch[\"token_type_ids\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            logits = model(\n",
    "                input_ids,\n",
    "                attention_mask,\n",
    "                token_type_ids,\n",
    "                batch[\"task_name\"][0]  # 单一任务\n",
    "            )\n",
    "          \n",
    "            loss = criterion(logits, batch[\"labels\"])\n",
    "            loss = loss / accumulation_steps  # 梯度累积\n",
    "            loss.backward() \n",
    "            if (i + 1) % accumulation_steps == 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "            running_loss += loss.item()\n",
    "           \n",
    "            loop.set_postfix(loss=loss.item())\n",
    "            total_batches += 1\n",
    "    epoch_loss = running_loss / total_batches\n",
    "    if (epoch_loss < best_loss):\n",
    "        best_loss = epoch_loss\n",
    "        checkpoint = {\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),              \n",
    "                'loss': epoch_loss,\n",
    "            }\n",
    "        torch.save(model.state_dict(), \"../model/MultiTaskBert/checkpoint_{epoch}.pth\")\n",
    "    print(f\"Epoch {epoch+1}/{epochs} 训练平均损失: {epoch_loss:.4f}\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c403cd5d",
   "metadata": {},
   "source": [
    "评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03902971",
   "metadata": {},
   "outputs": [],
   "source": [
    "evalers = { \"sst2\":sst2_eval, \"mnli\":mnli_eval, \"qqp\":qqp_eval }\n",
    "model.eval()\n",
    "\n",
    "for name,evaler in evalers.items():\n",
    "    metric_name = evaluate.load(\"glue\", name)\n",
    "    print(f\"开始评估 {name} 数据集\")\n",
    "    for batch in tqdm(evaler):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        token_type_ids = batch[\"token_type_ids\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(\n",
    "                input_ids,\n",
    "                attention_mask,\n",
    "                token_type_ids,\n",
    "                batch[\"task_name\"][0]  # 单一任务\n",
    "            )\n",
    "\n",
    "        logits = outputs\n",
    "        # model 返回的是 logits（不是一个带 logits 属性的对象），所以这里应该直接用 outputs\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        metric_name.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "\n",
    "    metric_name.compute()\n",
    "    print(f\"{name} 数据集评估完成\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "handonML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
